{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf438f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cm/Downloads/email_ingestion/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/cm/.cache/kagglehub/datasets/rasho330/job-application-email-anonymized-and-feature-rich/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rasho330/job-application-email-anonymized-and-feature-rich\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Get the CSV file path from the downloaded dataset directory\n",
    "file_path = os.path.join(path, os.listdir(path)[0])\n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48df7d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label_1 = df['email_body']\n",
    "Label_1 = Label_1.dropna().unique()\n",
    "Label_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bd2c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/cm/.cache/kagglehub/datasets/marcelwiechmann/enron-spam-data/versions/3\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"marcelwiechmann/enron-spam-data\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "file_path = os.path.join(path, os.listdir(path)[0])\n",
    "df_2 = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c970db31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out null messages\n",
    "df_2_clean = df_2[df_2['Message'].notna()]\n",
    "\n",
    "# Separate spam and ham\n",
    "spam_messages = df_2_clean[df_2_clean['Spam/Ham'] == 'spam'].sample(n=464, random_state=42)\n",
    "ham_messages = df_2_clean[df_2_clean['Spam/Ham'] == 'ham'].sample(n=464, random_state=42)\n",
    "\n",
    "# Combine them\n",
    "Label_0 = pd.concat([spam_messages['Message'], ham_messages['Message']]).reset_index(drop=True)\n",
    "Label_0.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eba2f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744    i ' m not familiar with the individual assets ...\n",
      "812    start date : 1 / 16 / 02 ; hourahead hour : 16...\n",
      "198    fyi , kim .\\n- - - - - original message - - - ...\n",
      "782    please find below the weekly project status up...\n",
      "346    start date : 2 / 6 / 02 ; hourahead hour : 24 ...\n",
      "672    - - - - - original message - - - - -\\nfrom : s...\n",
      "748    sally ,\\nattached is the detail of the analyst...\n",
      "645    darren :\\nena was invoiced by coral energy for...\n",
      "697    - - - - - - - - - - - - - - - - - - - - - - fo...\n",
      "382    start date : 2 / 6 / 02 ; hourahead hour : 24 ...\n",
      "Name: Message, dtype: str\n"
     ]
    }
   ],
   "source": [
    "print(Label_0.sample(n = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f064e480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.DataFrame"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate Label_0 and Label_1 into a single DataFrame with a label column\n",
    "df_label_0 = pd.DataFrame({'text': Label_0, 'is_job_related': 0})\n",
    "df_label_1 = pd.DataFrame({'text': Label_1, 'is_job_related': 1})\n",
    "\n",
    "combined_df = pd.concat([df_label_0, df_label_1], ignore_index=True)\n",
    "type(combined_df.sample(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0c669cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== #0 | is_job_related=1 =====\n",
      "Hi Michael Gary Scott,\n",
      " \n",
      "Thank you for your interest in Flip! We wanted to let you know we received your application for Data Scientist, and we are delighted that you would consider joining our team.\n",
      " \n",
      "Our team will review your application and will be in touch if your qualifications match our needs for the role. If you are not selected for this position, keep an eye on our jobs page as we're growing and adding openings.\n",
      " \n",
      "Best,\n",
      "The Flip Team\n",
      "\n",
      "===== #1 | is_job_related=0 =====\n",
      "louise ,\n",
      "thanks so much for your speedy reply . i will pass your comments on to dave walker in media relations .\n",
      "i included kevin because he is listed with you , greg and john on a \" management \" slide . if there are others who should be\n",
      "included on greg ' s core management team for the announcement , please let me know who they are and their titles . please\n",
      "also let me know if it is inappropriate to include kevin . if there is an org chart , that might be helpful , too . it would\n",
      "allow us to be as inclusive as possible without making the announcement too long .\n",
      "thanks again ,\n",
      "claudia\n",
      "212 - 713 - 8508\n",
      "- - - - - original message - - - - -\n",
      "from : louise . kitchen @ enron . com [ mailto : louise . kitchen @ enron . com ]\n",
      "sent : tuesday , february 05 , 2002 11 : 16 pm\n",
      "to : robinson , claudia ; petrie , james [ ubs ] ; eber , louis [ ubs ] ; brady ,\n",
      "penny [ ubs ] ; keily , ruth [ ubs ] ; mitchell , nikki [ ubs ] ;\n",
      "david . forster @ enron . com ; lloyd , andrew - d [ ubs ] ; hollis , amanda [ ubs ] ;\n",
      "odonnell , pat [ ubs ] ; dow , colette [ ubs ] ; louise @ enron . com ;\n",
      "kal . shah @ enron . com ; david . oxley @ enron . com ; martin , audrey [ ubs ]\n",
      "cc : bridges , mark [ ubs ]\n",
      "subject : re : releases\n",
      "just a couple of suggested changes to both .\n",
      "there is a lot of confusion in the energy market as to the ownership\n",
      "structure of the entity . enron had previously announced that the entiy\n",
      "would be 51 % new owner and 49 % enron . we need to ensure this message is\n",
      "corrected as clearly as possible - that it is 100 % ubs owner .\n",
      "( see attached file : ubsw energy release draft . doc )\n",
      "on the release for ubswenergy . com - we do intend to trade physical gas and\n",
      "power immediately initially at least in the areas we can , so i have removed\n",
      "that sentence .\n",
      "( see attached file : . doc )\n",
      "do you need all of the commercial md titles or is kevin picked out for a\n",
      "particular reason ?\n",
      "thanks\n",
      "louise\n",
      "- - - - - original message - - - - -\n",
      "from : \" robinson , claudia \" @ enron\n",
      "sent : tuesday , february 05 , 2002 7 : 45 pm\n",
      "to : petrie , james [ ubs ] ; eber , louis [ ubs ] ; brady , penny [ ubs ] ;\n",
      "keily , ruth [ ubs ] ; mitchell , nikki [ ubs ] ; forster , david ;\n",
      "lloyd , andrew - d [ ubs ] ; hollis , amanda [ ubs ] ; odonnell , pat\n",
      "[ ubs ] ; dow , colette [ ubs ] ; ' louise @ enron . com ' ; shah , kal ;\n",
      "oxley , david ; martin , audrey [ ubs ]\n",
      "cc : bridges , mark [ ubs ]\n",
      "subject : fw : releases\n",
      "attached for your review are drafts of two news releases , one announcing\n",
      "the closing of the ubs warburg / energy\n",
      "transaction and the other to announce the launch of ubswenergy . com . the\n",
      "plan is to issue the closing announcement on\n",
      "friday ( 2 / 8 ) at about 8 a . m . new york time . the other is planned for\n",
      "when the website officially launches , which is\n",
      "expected on monday ( 2 / 11 ) .\n",
      "please forward your comments directly to david p . walker , head of media\n",
      "relations - americas , sometime on wednesday .\n",
      "tomorrow , i will send you drafts of the internal announcements for\n",
      "friday and monday . the plan is to issue on friday a\n",
      "global ubs warburg email announcement from john costas , announcing the\n",
      "new management . i need from human resources\n",
      "confirmed titles for louise kitchen , john lavorato and kevin presto . in\n",
      "addition , we plan for friday an email from greg\n",
      "whalley to employees who have signed on with ubs warburg energy , with\n",
      "costas ' s announcement attached . ( both will also be\n",
      "posted on ubs warburg intranets , including the integration site . ) there\n",
      "will also be internal publicity on the day the\n",
      "website launches : another email from whalley to energy employees and\n",
      "intranet articles within ubs warburg , including the\n",
      "integration site .\n",
      "please let me know if you have questions .\n",
      "thanks ,\n",
      "claudia\n",
      "212 - 713 - 8508\n",
      "> > >\n",
      "- . doc >\n",
      "- ubsw energy release draft . doc >\n",
      "visit our website at http : / / www . ubswarburg . com\n",
      "this message contains confidential information and is intended only\n",
      "for the individual named . if you are not the named addressee you\n",
      "should not disseminate , distribute or copy this e - mail . please\n",
      "notify the sender immediately by e - mail if you have received this\n",
      "e - mail by mistake and delete this e - mail from your system .\n",
      "e - mail transmission cannot be guaranteed to be secure or error - free\n",
      "as information could be intercepted , corrupted , lost , destroyed ,\n",
      "arrive late or incomplete , or contain viruses . the sender therefore\n",
      "does not accept liability for any errors or omissions in the contents\n",
      "of this message which arise as a result of e - mail transmission . if\n",
      "verification is required please request a hard - copy version . this\n",
      "message is provided for informational purposes and should not be\n",
      "construed as a solicitation or offer to buy or sell any securities or\n",
      "related financial instruments .\n",
      "this e - mail is the property of enron corp . and / or its relevant affiliate and may contain confidential and privileged\n",
      "material for the sole use of the intended recipient ( s ) . any review , use , distribution or disclosure by others is\n",
      "strictly prohibited . if you are not the intended recipient ( or authorized to receive for the recipient ) , please contact\n",
      "the sender or reply to enron corp . at enron . messaging . administration @ enron . com and delete all copies of the message .\n",
      "this e - mail ( and any attachments hereto ) are not intended to be an offer ( or an acceptance ) and do not create or\n",
      "evidence a binding and enforceable contract between enron corp . ( or any of its affiliates ) and the intended recipient or\n",
      "any other party , and may not be relied on by anyone as the basis of a contract by estoppel or otherwise . thank you .\n",
      "visit our website at http : / / www . ubswarburg . com\n",
      "this message contains confidential information and is intended only\n",
      "for the individual named . if you are not the named addressee you\n",
      "should not disseminate , distribute or copy this e - mail . please\n",
      "notify the sender immediately by e - mail if you have received this\n",
      "e - mail by mistake and delete this e - mail from your system .\n",
      "e - mail transmission cannot be guaranteed to be secure or error - free\n",
      "as information could be intercepted , corrupted , lost , destroyed ,\n",
      "arrive late or incomplete , or contain viruses . the sender therefore\n",
      "does not accept liability for any errors or omissions in the contents\n",
      "of this message which arise as a result of e - mail transmission . if\n",
      "verification is required please request a hard - copy version . this\n",
      "message is provided for informational purposes and should not be\n",
      "construed as a solicitation or offer to buy or sell any securities or\n",
      "related financial instruments .\n",
      "\n",
      "===== #2 | is_job_related=1 =====\n",
      "Hello Michael Gary Scott ,\n",
      "Many thanks for applying to Deals - Data & Analytics Intern - Summer 2024 - Women's Consulting Experience .\n",
      "We regret to inform you that we will not be proceeding with your application to this role.\n",
      "On PwC's website, you're able to discover other jobs that may meet your career aspirations. New jobs are posted frequently, so check back often.\n",
      "Visit our careers page at www.pwc.com/jobs\n",
      "If you are a current PwC employee, please access \"Find Jobs\" report in Workday to see other available opportunities.\n",
      "We wish you all the best in your job search.\n",
      "PwC\n",
      "Network Structure Legal Entities Code of Conduct Member Firms Site Provider Legal Disclaimer ATS Privacy Statement Cookies Policy\n",
      "This email was intended for\n",
      "\n",
      "===== #3 | is_job_related=1 =====\n",
      "Hi Michael Gary Scott,\n",
      "Thank you for applying to Unlock Health. Your application has been received.\n",
      "Due to the high volume of applicants, we will only be reaching out regarding next steps if your application seems like a good fit for the position.\n",
      "Best regards,\n",
      "Unlock Health\n",
      "\n",
      "===== #4 | is_job_related=0 =====\n",
      "start date : 2 / 6 / 02 ; hourahead hour : 24 ; no ancillary schedules awarded . no variances detected .\n",
      "log messages :\n",
      "parsing file - - > > o : \\ portland \\ westdesk \\ california scheduling \\ iso final schedules \\ 2002020624 . txt\n",
      "! ! ! general sql error .\n",
      "couldn ' t update ; currently locked by user ' admin ' on machine ' nahou - trdts 5 ' .\n",
      "table\n",
      "- - - - energy import / export schedule - - - -\n",
      "* * * final schedule not found for preferred schedule .\n",
      "details :\n",
      "trans _ type : final\n",
      "sc _ id : ectstnw\n",
      "mkt _ type : 2\n",
      "trans _ date : 2 / 6 / 02\n",
      "tie _ point : malin _ 5 _ rndmtn\n",
      "interchg _ id : enrj _ ciso _ 3000\n",
      "engy _ type : firm\n",
      "\n",
      "===== #5 | is_job_related=1 =====\n",
      "Your application was sent to Airdrop                                                                                                                                                                \n",
      " \n",
      "\tMichael Gary Scott\n",
      "Your application was sent to Airdrop\n",
      "Airdrop \n",
      "Business Analyst\n",
      "Airdrop · San Francisco Bay Area\n",
      "Applied: 5 seconds ago\n",
      "View similar jobs you may be interested in\n",
      "Microsoft \n",
      "Data Scientist\n",
      "Microsoft · Redmond, WA\n",
      "Optomi \n",
      "Entry Level Data Analyst - SQL\n",
      "Optomi · Dallas, TX\n",
      "Microsoft \n",
      "Data Scientist\n",
      "Microsoft · Redmond, WA\n",
      "See more\n",
      " \n",
      "\t\n",
      " \n",
      "This email was intended for Michael Gary Scott (Data Analytics Graduate | Data Science, Analysis, Storytelling | Crafting Data-Driven Narratives for Informed Decision-Making). Learn why we included this.\n",
      " \n",
      "You are receiving Job Application Confirmation emails.\n",
      "\n",
      "===== #6 | is_job_related=1 =====\n",
      "Rivian \n",
      "Hi Michael Gary Scott,\n",
      " \n",
      "Thank you for your application to Rivian. We are writing to let you know that we have filled the Data Engineering and Analytics, Summer 2024 Internships position. \n",
      " \n",
      "If you applied to multiple roles, your applications are being evaluated separately. This notice is only for the Data Engineering and Analytics, Summer 2024 Internships  role. \n",
      " \n",
      "We appreciate your interest in joining us, and we will contact you in the future if we identify another position that matches your experience and strengths. We encourage you to watch our Careers site and \n",
      " \n",
      "Thank you again for your interest in Rivian and good luck in your job search! \n",
      " \n",
      "Thank you,  \n",
      " \n",
      "The Recruiting Team at Rivian\n",
      " \n",
      "This message was sent to . If you don't want to receive these emails from this company in the future, please go\n",
      "\n",
      "===== #7 | is_job_related=0 =====\n",
      "the meeting will be held on december 8 , 2000 from 11 : 30 am to 1 : 00 pm in\n",
      "conference room eb 19 cl . box lunches will be served . your choices are\n",
      "listed below :\n",
      "salads : roasted chicken cobb salad , grilled chicken caesar salad , classic\n",
      "chef salad\n",
      "sandwiches : turkey , roast beef , ham , chicken salad , tuna salad or club\n",
      "sandwich . served on homemade white or wheat bread\n",
      "please email your lunch choice to me by monday , december 4 , 2000 .\n",
      "thanks and regards ,\n",
      "anita dupont\n",
      "\n",
      "===== #8 | is_job_related=0 =====\n",
      "i tried calling you this am but your phone rolled to someone else ' s voicemail . can you call me when you get a chance ?\n",
      "- - - - - original message - - - - -\n",
      "from : farmer , daren j .\n",
      "sent : thursday , january 10 , 2002 2 : 06 pm\n",
      "to : hill , garrick\n",
      "subject : re : tenaska iv\n",
      "rick ,\n",
      "i ' ve had a couple of meetings today . i ' m sorry i ' m just getting back to you . i tried to call but the voice mail said that you were unavailable . so , give me a call when you get a chance .\n",
      "d\n",
      "- - - - - original message - - - - -\n",
      "from : hill , garrick\n",
      "sent : wednesday , january 09 , 2002 6 : 11 pm\n",
      "to : farmer , daren j .\n",
      "subject : re : tenaska iv\n",
      "i ' ll call you on thursday . . . what ' s a good time ?\n",
      "- - - - - original message - - - - -\n",
      "from : farmer , daren j .\n",
      "sent : wednesday , january 09 , 2002 3 : 03 pm\n",
      "to : hill , garrick\n",
      "cc : olsen , michael\n",
      "subject : tenaska iv\n",
      "rick ,\n",
      "we need to talk about the ability of ena to continue its the current role as agent of tenaska iv .\n",
      "1 ) since the end on november , ena has not been able to complete gas trading transactions . we cannot find any counterparties to trade physical gas in texas . this , of course , is due to the bankruptcy . as a result , we are not able to sale tenaska ' s excess fuel . we did contact brazos to ask if they would buy a portion of the gas at a gas daily price , but they do not want it ( gas daily pricing has been below the firm contract price for a while ) . in december , we had to cut 10 , 000 / day from the 7 th through the 27 th . for january , we haven ' t had to cut yet , but i am sure that the pipe will ask us to do this in the near future .\n",
      "2 ) for november activity ( which was settled in dec ) , ena owes tenaska iv for the excess supply that we sold . however , due to the bankruptcy , we could not make payments out . ena could not pay the suppliers or the pipeline . james armstrong paid the counterparties directly . i think that he should continue to do this for dec and jan . we should not transfer any funds from tenaska iv to ena .\n",
      "i don ' t know how enron ' s ownership in the plant factors out in the bankruptcy preceding . but we need to determine how to go forward with the fuel management .\n",
      "please give me a call or e - mail me . we can get together sometime thurs or fri morning .\n",
      "d\n",
      "\n",
      "===== #9 | is_job_related=1 =====\n",
      "Thanks for applying for a career at Live Nation Entertainment! You have applied for the Pricing Data Analyst Internship position and have now begun the application process. At this point, your skills and qualifications are being reviewed. If you are selected to move forward, you will be contacted. Either way, we sincerely wish you all the best.\n",
      "This email was intended for\n"
     ]
    }
   ],
   "source": [
    "sample_df = combined_df.sample(n=10, random_state=42).reset_index(drop=True)\n",
    "\n",
    "for i, row in sample_df.iterrows():\n",
    "    print(f\"\\n===== #{i} | is_job_related={row['is_job_related']} =====\")\n",
    "    print(row[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a99c3bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET OVERVIEW\n",
      "================================================================================\n",
      "\n",
      "Dataset shape: (1392, 2)\n",
      "Total samples: 1392\n",
      "\n",
      "Column names and types:\n",
      "text                str\n",
      "is_job_related    int64\n",
      "dtype: object\n",
      "\n",
      "================================================================================\n",
      "MISSING VALUES\n",
      "================================================================================\n",
      "text              0\n",
      "is_job_related    0\n",
      "dtype: int64\n",
      "Missing values percentage:\n",
      "text              0.0\n",
      "is_job_related    0.0\n",
      "dtype: float64\n",
      "\n",
      "================================================================================\n",
      "CLASS DISTRIBUTION\n",
      "================================================================================\n",
      "is_job_related\n",
      "0    928\n",
      "1    464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution (%):\n",
      "is_job_related\n",
      "0    66.67\n",
      "1    33.33\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "TEXT STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Character count statistics:\n",
      "count     1392.000000\n",
      "mean      1296.738506\n",
      "std       2518.032197\n",
      "min         14.000000\n",
      "25%        541.750000\n",
      "50%        839.500000\n",
      "75%       1180.000000\n",
      "max      68196.000000\n",
      "Name: text_length, dtype: float64\n",
      "\n",
      "Word count statistics:\n",
      "count     1392.000000\n",
      "mean       270.890086\n",
      "std        505.726906\n",
      "min          3.000000\n",
      "25%         94.000000\n",
      "50%        151.000000\n",
      "75%        325.000000\n",
      "max      13428.000000\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "Text length by class:\n",
      "               text_length                                                 \\\n",
      "                     count     mean      std   min     25%    50%     75%   \n",
      "is_job_related                                                              \n",
      "0                    928.0  1573.54  3030.96  14.0  632.00  868.0  1666.5   \n",
      "1                    464.0   743.13   441.49  43.0  478.75  681.5   887.0   \n",
      "\n",
      "                        word_count                                             \\\n",
      "                    max      count    mean     std  min    25%    50%     75%   \n",
      "is_job_related                                                                  \n",
      "0               68196.0      928.0  344.59  603.76  3.0  151.0  173.0  355.00   \n",
      "1                4535.0      464.0  123.48   76.64  7.0   80.0  104.5  139.25   \n",
      "\n",
      "                         \n",
      "                    max  \n",
      "is_job_related           \n",
      "0               13428.0  \n",
      "1                 702.0  \n",
      "\n",
      "================================================================================\n",
      "SAMPLE INSPECTION\n",
      "================================================================================\n",
      "\n",
      "Job-related email sample (is_job_related=1):\n",
      "Hello Micheal Gary Scott, \n",
      " \n",
      "We’ve received your application for the Decision Scientist position at Tesco. Thank you for taking the time to apply and for considering joining us. \n",
      " \n",
      "So, what happens next? \n",
      " \n",
      "First of all, our recruitment team will take a look at your application – if your skills and experience match the position, we’ll get in touch to arrange next steps. \n",
      " \n",
      "We know how much effort it takes to put together an application, so we review each one carefully. As soon as we’ve got any n\n",
      "\n",
      "Non job-related email sample (is_job_related=0):\n",
      "louise ,\n",
      "thanks so much for your speedy reply . i will pass your comments on to dave walker in media relations .\n",
      "i included kevin because he is listed with you , greg and john on a \" management \" slide . if there are others who should be\n",
      "included on greg ' s core management team for the announcement , please let me know who they are and their titles . please\n",
      "also let me know if it is inappropriate to include kevin . if there is an org chart , that might be helpful , too . it would\n",
      "allow us to be\n"
     ]
    }
   ],
   "source": [
    "# Display basic dataset information\n",
    "print(\"=\"*80)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset shape: {combined_df.shape}\")\n",
    "print(f\"Total samples: {len(combined_df)}\")\n",
    "print(f\"\\nColumn names and types:\")\n",
    "print(combined_df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MISSING VALUES\")\n",
    "print(\"=\"*80)\n",
    "print(combined_df.isnull().sum())\n",
    "print(f\"Missing values percentage:\\n{(combined_df.isnull().sum() / len(combined_df) * 100).round(2)}\")\n",
    "\n",
    "# Class distribution\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLASS DISTRIBUTION\")\n",
    "print(\"=\"*80)\n",
    "print(combined_df['is_job_related'].value_counts())\n",
    "print(f\"\\nClass distribution (%):\")\n",
    "print((combined_df['is_job_related'].value_counts(normalize=True) * 100).round(2))\n",
    "\n",
    "# Text statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEXT STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "combined_df['text_length'] = combined_df['text'].astype(str).apply(len)\n",
    "combined_df['word_count'] = combined_df['text'].astype(str).apply(lambda x: len(x.split()))\n",
    "\n",
    "print(f\"\\nCharacter count statistics:\")\n",
    "print(combined_df['text_length'].describe())\n",
    "print(f\"\\nWord count statistics:\")\n",
    "print(combined_df['word_count'].describe())\n",
    "\n",
    "print(f\"\\nText length by class:\")\n",
    "print(combined_df.groupby('is_job_related')[['text_length', 'word_count']].describe().round(2))\n",
    "\n",
    "# Sample inspection\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE INSPECTION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nJob-related email sample (is_job_related=1):\")\n",
    "print(combined_df[combined_df['is_job_related'] == 1]['text'].iloc[0][:500])\n",
    "print(f\"\\nNon job-related email sample (is_job_related=0):\")\n",
    "print(combined_df[combined_df['is_job_related'] == 0]['text'].iloc[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "034575f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_email(text: str, head: int = 3000, tail: int = 1000) -> str:\n",
    "    text = str(text).strip()\n",
    "    if len(text) <= head + tail:\n",
    "        return text\n",
    "    return text[:head] + \"\\n\\n[TRUNCATED]\\n\\n\" + text[-tail:]\n",
    "\n",
    "combined_df[\"text_clipped\"] = combined_df[\"text\"].apply(clip_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70c45e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_ws(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = s.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
    "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    return s.strip()\n",
    "\n",
    "combined_df[\"text_clipped\"] = combined_df[\"text_clipped\"].apply(normalize_ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c8c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags\n",
      "NO_IGNORE    928\n",
      "YES_TRACK    464\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = combined_df.copy()\n",
    "\n",
    "df[\"Text\"] = df[\"text\"].astype(str).str.strip()\n",
    "df[\"Tags\"] = df[\"is_job_related\"].map({1: \"YES_TRACK\", 0: \"NO_IGNORE\"})\n",
    "\n",
    "out = df[[\"Text\", \"Tags\"]]\n",
    "out.to_csv(\"labeling/train_dataverse.csv\", index=False, encoding=\"utf-8\")\n",
    "print(out[\"Tags\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf681ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
